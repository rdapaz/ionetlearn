{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Binary Classification with DNS and Combined Dataset\n",
    "\n",
    "Characteristics of this notebook include:\n",
    "\n",
    "  * Combined dataset used\n",
    "  * Tokenizing 300 words from DNS queries based on freq\n",
    "  * No Geolocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore previously saved df_sample DataFrame\n",
    "\n",
    "In order to allow us to commence our training without having to repeat the previous data preparation steps, we will now load the df_sample dataframe using the pandas built-in from_json method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loaded pandas dataframe from disk in 4.15 secs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "cwd = Path.cwd()\n",
    "\n",
    "file_path = os.path.join(cwd, 'saved_datasets', 'combined_dataset_dns.json' )\n",
    "df_sample = pd.read_json(file_path)\n",
    "end = time()\n",
    "print(f\"[+] Loaded pandas dataframe from disk in {(end-start):.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the fun starts here...\n",
    "\n",
    "We'll split the dataset as follows:\n",
    "\n",
    "1. Training set (80%)\n",
    "2. Test set (20%)\n",
    "3. We have not set up a validation set as we will continue to validate the model against new captures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df_sample['is_iot'] = np.where(df_sample['device_type'] == 'Other', 0, 1)\n",
    "df_sample.drop('device_type', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_sample.drop('is_iot', axis=1).values\n",
    "labels = df_sample['is_iot'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32799::26239::6560\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), len(Y_train), len(Y_test), sep='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5092987804878049"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  This is new\n",
    "from sklearn.dummy import DummyClassifier\n",
    "bm = DummyClassifier()\n",
    "bm.fit(X_train, Y_train)\n",
    "bm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Problems\n",
    "\n",
    "*A quick recap of the various hyper-parameters to be used in the model for each type of classification problem:*\n",
    "\n",
    "**Binary Classification Problem**\n",
    "\n",
    "A problem where you classify an example as belonging to one of two classes.\n",
    "\n",
    "The problem is framed as predicting the likelihood of an example belonging to class one, e.g. the class that you assign the integer value 1, whereas the other class is assigned the value 0.\n",
    "\n",
    " - Output Layer Configuration: `One node with a sigmoid activation unit`.\n",
    " - Loss Function: `Cross-Entropy`, also referred to as Logarithmic loss.\n",
    "\n",
    "**Multi-Class Classification Problem**\n",
    "\n",
    "A problem where you classify an example as belonging to one of more than two classes.\n",
    "\n",
    "The problem is framed as predicting the likelihood of an example belonging to each class.\n",
    "\n",
    " - Output Layer Configuration: `One node for each class using the softmax activation function`.\n",
    " - Loss Function: `Cross-Entropy`, also referred to as Logarithmic loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "class ModelFactory():\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.params = args\n",
    "        print(f'[+] Initialised with params: {self.params}')\n",
    "        if 'model_name' in kwargs:\n",
    "            self.model_name = kwargs['model_name']\n",
    "\n",
    "    def get_model(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.params[0], input_dim=features.shape[1], activation='relu'))\n",
    "        if len(self.params) > 1:\n",
    "            for it in self.params[1:]:\n",
    "                eval(f\"model.add(Dense({it}, activation='relu'))\")\n",
    "                eval(f\"model.add(Dropout(0.2))\")\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, \n",
    "                                verbose=1, mode='auto', restore_best_weights=True)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Initialised with params: (64, 128, 64)\n",
      "[+] Initialised with params: (32, 64, 32)\n",
      "Epoch 1/67\n",
      " - 5s - loss: 0.1093 - accuracy: 0.9550\n",
      "Epoch 2/67\n",
      " - 5s - loss: 0.0686 - accuracy: 0.9716\n",
      "Epoch 3/67\n",
      " - 5s - loss: 0.0627 - accuracy: 0.9731\n",
      "Epoch 4/67\n",
      " - 5s - loss: 0.0599 - accuracy: 0.9752\n",
      "Epoch 5/67\n",
      " - 5s - loss: 0.0569 - accuracy: 0.9759\n",
      "Epoch 6/67\n",
      " - 5s - loss: 0.0550 - accuracy: 0.9776\n",
      "Epoch 7/67\n",
      " - 5s - loss: 0.0529 - accuracy: 0.9774\n",
      "Epoch 8/67\n",
      " - 5s - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 9/67\n",
      " - 5s - loss: 0.0529 - accuracy: 0.9774\n",
      "Epoch 10/67\n",
      " - 5s - loss: 0.0524 - accuracy: 0.9777\n",
      "Epoch 11/67\n",
      " - 5s - loss: 0.0512 - accuracy: 0.9776\n",
      "Epoch 12/67\n",
      " - 5s - loss: 0.0508 - accuracy: 0.9781\n",
      "Epoch 13/67\n",
      " - 5s - loss: 0.0504 - accuracy: 0.9782\n",
      "Epoch 14/67\n",
      " - 5s - loss: 0.0508 - accuracy: 0.9785\n",
      "Epoch 15/67\n",
      " - 5s - loss: 0.0499 - accuracy: 0.9789\n",
      "Epoch 16/67\n",
      " - 5s - loss: 0.0500 - accuracy: 0.9790\n",
      "Epoch 17/67\n",
      " - 5s - loss: 0.0505 - accuracy: 0.9792\n",
      "Epoch 18/67\n",
      " - 5s - loss: 0.0497 - accuracy: 0.9784\n",
      "Epoch 19/67\n",
      " - 5s - loss: 0.0487 - accuracy: 0.9784\n",
      "Epoch 20/67\n",
      " - 5s - loss: 0.0491 - accuracy: 0.9789\n",
      "Epoch 21/67\n",
      " - 5s - loss: 0.0494 - accuracy: 0.9788\n",
      "Epoch 22/67\n",
      " - 5s - loss: 0.0479 - accuracy: 0.9792\n",
      "Epoch 23/67\n",
      " - 5s - loss: 0.0484 - accuracy: 0.9785\n",
      "Epoch 24/67\n",
      " - 5s - loss: 0.0482 - accuracy: 0.9788\n",
      "Epoch 25/67\n",
      " - 5s - loss: 0.0485 - accuracy: 0.9790\n",
      "Epoch 26/67\n",
      " - 5s - loss: 0.0483 - accuracy: 0.9786\n",
      "Epoch 27/67\n",
      " - 5s - loss: 0.0482 - accuracy: 0.9785\n",
      "Epoch 28/67\n",
      " - 5s - loss: 0.0487 - accuracy: 0.9790\n",
      "Epoch 29/67\n",
      " - 5s - loss: 0.0481 - accuracy: 0.9787\n",
      "Epoch 30/67\n",
      " - 5s - loss: 0.0479 - accuracy: 0.9791\n",
      "Epoch 31/67\n",
      " - 5s - loss: 0.0483 - accuracy: 0.9788\n",
      "Epoch 32/67\n",
      " - 5s - loss: 0.0475 - accuracy: 0.9793\n",
      "Epoch 33/67\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "NEEDS_TRAINING = True\n",
    "\n",
    "if NEEDS_TRAINING:\n",
    "\n",
    "    model_a = ( ModelFactory(64,128,64).get_model(), 'ModelA' )\n",
    "    model_b = ( ModelFactory(32,64,32).get_model(),  'ModelB' )\n",
    "\n",
    "    histories = []\n",
    "\n",
    "    for my_mod in [model_a, model_b]: \n",
    "        mod, mod_name = my_mod\n",
    "        history = mod.fit(X_train, Y_train, epochs=67, batch_size=10, shuffle=True, verbose=2)\n",
    "        # Serialise model to json\n",
    "        model_json = mod.to_json()\n",
    "        filepath = os.path.join(\n",
    "                                cwd,\n",
    "                                'saved_models',\n",
    "                                f'{mod_name}_binary_dns.json'\n",
    "                                )\n",
    "        with open(filepath, \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "\n",
    "        # Serialize weights to HDF5\n",
    "        filepath = os.path.join(\n",
    "                            cwd,\n",
    "                            'saved_models',\n",
    "                            f'{mod_name}_binary_dns.h5'\n",
    "                            )\n",
    "        mod.save_weights(filepath)\n",
    "        loss, accuracy = mod.evaluate(X_test, Y_test, verbose=2)\n",
    "        print(f'{my_mod[1]}: Loss = {loss}, Accuracy={accuracy}')\n",
    "        histories.append([history, loss, accuracy])\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "LEGEND = False\n",
    "\n",
    "if NEEDS_TRAINING:\n",
    "\n",
    "    for idx, hist_data in enumerate(histories, 1):\n",
    "        history, loss, accuracy = hist_data\n",
    "        # Plot training & validation accuracy values\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(1,2,1)\n",
    "        ax1.plot(history.history['accuracy'], color='black')\n",
    "        plt.title(f'Model {idx} Accuracy: {(accuracy*100.0):.2f}', fontsize=16, fontweight='bold')\n",
    "        plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "        if LEGEND: ax1.legend('Train', loc='upper left')\n",
    "\n",
    "        # # Plot training & validation loss values\n",
    "        ax2 = fig.add_subplot(1,2,2)\n",
    "        ax2.plot(history.history['loss'], color='black')\n",
    "        plt.title(f'Model {idx} Loss', fontsize=16, fontweight='bold')\n",
    "        plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "        if LEGEND: ax2.legend('Train', loc='upper left')\n",
    "        plt.savefig(f'/home/ricdeez/uni/projects/iotnetlearn/binary{idx}_dns.png', dpi=150)\n",
    "        plt.show()\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "\n",
    "json_file = open(\n",
    "                os.path.join(\n",
    "                    cwd,\n",
    "                    'saved_models',\n",
    "                    'ModelB_binary.json'\n",
    "                ), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.join(cwd, 'saved_models', 'ModelB_binary.h5'))\n",
    "print(\"[+] Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions were adapted from:\n",
    "#  Jeff Heaton, McKelvey School of Engineering, Washington University in St. Louis\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_roc(pred,y):\n",
    "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "    plt.rcParams[\"figure.dpi\"] = 150\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'/home/ricdeez/uni/projects/iotnetlearn/roc_binary.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(X_test)\n",
    "pred = np.where(pred >= 0.5, 1, 0)\n",
    "plot_roc(pred,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Classification Accuracy\n",
    "\n",
    "Accuracy refers to the number of rows in our dataset where the model predicted the target class.  Accuracy is only used for classification, not regression.\n",
    "\n",
    "\\begin{align}\n",
    "accuracy = \\frac{c}{N}\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    " * c is the number correct, and\n",
    " * N is the size of the evaluated set\n",
    " \n",
    "Keras returns the probability percentage for each class.  We'll change these into actual model predictions with n.where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(X_test)\n",
    "pred = np.where(pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_predict = loaded_model.predict(X_test)\n",
    "y_predict = np.where(y_predict >= 0.5, 1, 0)\n",
    "cm_df = pd.DataFrame(\n",
    "    confusion_matrix(Y_test, y_predict),\n",
    "        columns = [\n",
    "            'Predict Non-IoT',\n",
    "            'Predict IoT'\n",
    "        ],\n",
    "        index = [\n",
    "            'True Non-IoT',\n",
    "            'True IoT'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cm_df, ['Non-IoT', 'IoT'])\n",
    "plt.savefig(f'/home/ricdeez/uni/projects/iotnetlearn/confusion_matrix_binary_dns.png', dpi=150)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
